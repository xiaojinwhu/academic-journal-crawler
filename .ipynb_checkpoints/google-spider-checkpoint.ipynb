{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pymysql as ps\n",
    "import time\n",
    "import socket\n",
    "import socks\n",
    "\n",
    "\n",
    "class GooSpider():\n",
    "    def __init__(self, query_sting, start=10):\n",
    "        self.query_sting = query_sting\n",
    "        self.headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "        }\n",
    "        self.start = start\n",
    "\n",
    "    def _get_response(self,url='https://scholar.google.com.hk/scholar'):\n",
    "        \n",
    "        proxies = {\n",
    "                   'http' : 'http://127.0.0.1:8087',\n",
    "                   'https': 'https://127.0.0.1:8087'\n",
    "                  }\n",
    "        \n",
    "\n",
    "        query_generator = {\n",
    "            \"q\": self.query_sting,\n",
    "            \"start\": self.start\n",
    "        }\n",
    "        response = requests.get(url, headers=self.headers, params=query_generator)  # proxies=proxies\n",
    "        print(response.status_code)\n",
    "        html = response.text\n",
    "        \n",
    "        return html\n",
    "\n",
    "    def get_articles(self):\n",
    "        soup = BeautifulSoup(self._get_response(), \"lxml\")\n",
    "        total_pages = len(soup.find_all('td'))-2\n",
    "        articles = []\n",
    "        for item in soup.find_all('div', class_='gs_r'):\n",
    "            article_title = item.h3.get_text().replace('[HTML][HTML] ', '')\n",
    "            ref_item = item.find('div', class_='gs_ggsd')\n",
    "            article_ref = ref_item.a.get('href') if ref_item else 'null'\n",
    "            citation = ''\n",
    "            article_list = [datetime.now(), article_title, article_ref, self.query_sting, citation]\n",
    "            articles.append(article_list)\n",
    "        #print(articles)\n",
    "        return articles, total_pages\n",
    "    def get_pdf(self):\n",
    "        #print(self.get_articles()[0][2])\n",
    "        for i,li in enumerate(self.get_articles()[0]):            \n",
    "            if li[2].endswith('.pdf'):\n",
    "                try:\n",
    "                    find_pdf = requests.get(li[2], headers=self.headers, verify = False).content\n",
    "                    time.sleep(3)\n",
    "                    pdf_name = li[2].split('/')[-1]\n",
    "                    print(li[2])\n",
    "                    root = 'D://'\n",
    "                    path = root + pdf_name\n",
    "                    time.sleep(10)\n",
    "                    with open(path, 'wb') as f:\n",
    "                        f.write(find_pdf)\n",
    "                        print('PDF保存成功')\n",
    "                        f.close()\n",
    "                except:\n",
    "                    print('有点问题,采取sci-hub试试')\n",
    "#             else:\n",
    "#                 print('尝试通过sci-hub下载，希望不要出现验证码')\n",
    "#                 #try:\n",
    "#                 url_to_sci = 'http://sci-hub.cc/'+li[1]\n",
    "#                 find_pdf = requests.get(url_to_sci, headers=self.headers, verify = False).status_code #verify = False\n",
    "#                 print(find_pdf)\n",
    "# #                 except:\n",
    "# #                     print('很遗憾，sci-hub也下不下来')\n",
    "\n",
    "        print('文献下载完成')\n",
    "        print(self.get_articles()[1])\n",
    "            \n",
    "        \n",
    "\n",
    "def insert_to_db(articles):\n",
    "    db_config = {\n",
    "        'host': '10.10.172.41',\n",
    "        'port': 3306,\n",
    "        'user': 'xj',\n",
    "        'password': 'xj3d',\n",
    "        'db': 'dspdw_dev',\n",
    "        'charset': 'utf8'\n",
    "    }\n",
    "    db = ps.connect(**db_config)\n",
    "    cursor = db.cursor()\n",
    "    print('数据库连接成功')\n",
    "    insert_to_article = \"INSERT INTO article VALUES(%s, %s, %s,%s, %s)\"\n",
    "    try:\n",
    "        cursor.executemany(insert_to_article, articles)\n",
    "        db.commit()\n",
    "        print('数据导入成功')\n",
    "    except:\n",
    "        db.rollback()\n",
    "        print('不知道哪儿出错')\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "goo = GooSpider('egfr')\n",
    "articles = goo.get_articles()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_to_db(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_scihub(articles):\n",
    "    headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "        }\n",
    "    for i, article in enumerate(articles): \n",
    "        print(article)\n",
    "        url_to_sci = 'http://sci-hub.cc/'+article[1]\n",
    "        \n",
    "        r = requests.get(url_to_sci, headers=headers)\n",
    "        if r.headers['Content-Type'] == 'application/pdf':  \n",
    "            root = 'D://'\n",
    "            path = root + article[1] + '.pdf'\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "                print('PDF保存成功')\n",
    "                f.close()\n",
    "            time.sleep(3)\n",
    "#         else:\n",
    "#             soup = BeautifulSoup(find_pdf_url,'lxml')\n",
    "#             print(soup.find('iframe')['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 462070), 'Surface plasmon resonance scattering and absorption of anti-EGFR antibody conjugated gold nanoparticles in cancer diagnostics: applications in oral cancer', 'http://wiki.phy.queensu.ca/shughes/images/6/60/SPR_Scattering.pdf', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 462070), 'Genotypic and histological evolution of lung cancers acquiring resistance to EGFR inhibitors', 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3132801/', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 463070), 'MET amplification occurs with or without T790M mutations in EGFR mutant lung tumors with acquired resistance to gefitinib or erlotinib', 'http://www.pnas.org/content/104/52/20932.full', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 463070), 'Selective laser photo-thermal therapy of epithelial carcinoma using anti-EGFR antibody conjugated gold nanoparticles', 'https://www.researchgate.net/profile/Mostafa_El-Sayed/publication/7567168_Selective_Laser_Photo-Thermal_Therapy_of_Epithelial_Carcinoma_Using_Anti-EGFR_Antibody_Conjugated_Gold_Nanoparticles/links/5470ae820cf2d67fc031a963.pdf', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 463070), 'Unresponsiveness of colon cancer to BRAF (V600E) inhibition through feedback activation of EGFR', 'http://www.academia.edu/download/39682946/Unresponsiveness_of_colon_cancer_to_BRAF20151104-8710-3d9exc.pdf', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 463070), 'Phase III study of afatinib or cisplatin plus pemetrexed in patients with metastatic lung adenocarcinoma with EGFR mutations', 'http://ascopubs.org/doi/full/10.1200/jco.2012.44.2806', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 464071), 'EGFR antagonists in cancer treatment', 'https://pdfs.semanticscholar.org/80d5/baaaaabc3fb40a73f0ad4a597114f77be4ea.pdf', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 464071), 'The T790M mutation in EGFR kinase causes drug resistance by increasing the affinity for ATP', 'http://www.pnas.org/content/105/6/2070.full', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 464071), 'The molecular evolution of acquired resistance to targeted EGFR blockade in colorectal cancers', 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3436069/', 'egfr', '']\n",
      "[datetime.datetime(2017, 9, 12, 17, 55, 36, 465072), 'Detection of mutations in EGFR in circulating lung-cancer cells', 'http://www.nejm.org/doi/full/10.1056/NEJMoa0800668', 'egfr', '']\n"
     ]
    }
   ],
   "source": [
    "get_pdf_scihub(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
